{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constants:\n",
    "    schema = \"euromonitor\"\n",
    "    table = \"marketsize\"\n",
    "\n",
    "    key_name = f\"org_raw_{schema}_{table}\"\n",
    "    tmp = f\"/tmp/{key_name}/\"\n",
    "\n",
    "    base_url = \"https://api.euromonitor.com\"\n",
    "    endpoint_auth = \"/authentication/connect/token\"\n",
    "    endpoint_category = \"/catalog/category\"\n",
    "    endpoint_geography = \"/catalog/geography\"\n",
    "    endpoint_marketsize = '/statistics/marketsizes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(email: str, password: str, subscription_key: str) -> str:\n",
    "    \"\"\"Obtem o token de autenticação dos endpoints da API.\"\"\"\n",
    "    logging.info(\"Obtendo token de autenticação\")\n",
    "\n",
    "    header = {\n",
    "        #'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "        \"Accept\": \"application/json; api-version=1.0\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "    }\n",
    "    body = {\"grant_type\": \"string\", \"username\": email, \"password\": password}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"\".join([Constants.base_url, Constants.endpoint_auth]),\n",
    "            headers=header,\n",
    "            data=body,\n",
    "        )\n",
    "\n",
    "        if not response.status_code == 200:\n",
    "            raise Exception(\n",
    "                'API Euromonitor retornou um status inválido '\n",
    "                + f'{response.status_code}: {response.reason}!\\n'\n",
    "                + response.text\n",
    "            )\n",
    "        if not response.content:\n",
    "            raise Exception(\n",
    "                \"API Euromonitor não retornou um conteúdo para chamda HTTP!\"\n",
    "            )\n",
    "\n",
    "        content = response.json()\n",
    "\n",
    "        if not all([key in content.keys() for key in [\"access_token\", \"token_type\"]]):\n",
    "            raise Exception(\"API Euromonitor não retornou um token de acesso!\")\n",
    "    except Exception as err:\n",
    "        raise Exception(f\"Falha ao tentar obter token de consulta. Erro: {err}\")\n",
    "\n",
    "    api_token = \" \".join([content.get(\"token_type\"), content.get(\"access_token\")])\n",
    "    logging.info('Token obtido com sucesso')\n",
    "    return api_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(iterable, n: int = 1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx: min(ndx + n, l)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(**kwargs):\n",
    "    \"\"\"Esta função realizado captura de dados da API Sidra:\n",
    "    Dados gerais das empresas industriais com 1 ou mais pessoas ocupadas, segundo as\n",
    "    divisões de atividades (CNAE 2.0).\n",
    "    \"\"\"\n",
    "    bot = initialize()\n",
    "    LND: str = bot.lnd\n",
    "    adl: FileSystemClient = bot.adl\n",
    "\n",
    "    os.makedirs(Constants.tmp, mode=0o777, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        if kwargs[\"reset\"] is True:\n",
    "            call_redis(\"delete\", Constants.key_name)\n",
    "\n",
    "        if kwargs[\"reload\"] is True:\n",
    "            raise Exception(\"Este crawler não suporta a opção de reload\")\n",
    "\n",
    "        if call_redis(\"exists\", Constants.key_name):\n",
    "            _date_str = call_redis(\"get\", Constants.key_name).decode()\n",
    "            last_update = datetime.strptime(_date_str, \"%Y-%m-%d\").date()\n",
    "        else:\n",
    "            last_update = None\n",
    "\n",
    "        secret_client = bot.secret_client\n",
    "        email = secret_client.get_secret('euromonitor-email').value\n",
    "        password = secret_client.get_secret('euromonitor-pw').value\n",
    "        subscription_key = secret_client.get_secret('euromonitor-key').value\n",
    "\n",
    "        api_token = get_token(email, password, subscription_key)\n",
    "\n",
    "        header = {\n",
    "            \"Accept\": \"application/json; api-version=1.0\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "            \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "            \"Authorization\": api_token,\n",
    "        }\n",
    "\n",
    "        ### Consulta principal de marketsize\n",
    "\n",
    "        cat_ids = ['84']\n",
    "        geo_ids = ['195', '259', '310', '380', '182', '389']\n",
    "\n",
    "        df = None\n",
    "        j=1\n",
    "        for cat_id_chunk in chunker(cat_ids, 100):\n",
    "            c=1\n",
    "            for geo_id_chunk in chunker(geo_ids, 100):\n",
    "                has_more = True\n",
    "                offset = 0\n",
    "                while(has_more):\n",
    "                    logging.info(f'Offset: {offset}')\n",
    "                    try:\n",
    "                        payload = {\n",
    "                            \"categoryIds\" : [cat_id_chunk],\n",
    "                            \"geographyIds\": geo_id_chunk,\n",
    "                            \"limit\": '10000',\n",
    "                            \"offset\": str(offset)\n",
    "                        }\n",
    "                        logging.info(\n",
    "                            f'Extraindo dados da API Euromonitor. CatChunck: {j}. GeoChunk: {c}'\n",
    "                        )\n",
    "                        endpoint = Constants.endpoint_marketsize.format(\n",
    "                            geo=','.join(geo_ids), cat=','.join(cat_ids)\n",
    "                        )\n",
    "                        \n",
    "                        response = requests.post(\n",
    "                            ''.join([Constants.base_url, endpoint]),\n",
    "                            headers=header,\n",
    "                            data=payload\n",
    "                        )\n",
    "                        if response.status_code == 403:\n",
    "                            logging.warning(f'Sem autorização para essa query.')\n",
    "                            has_more=False\n",
    "                            sleep(1)\n",
    "                            continue\n",
    "                        if response.status_code == 204:\n",
    "                            logging.warning(f'Sem Registros para essa query.')\n",
    "                            has_more=False\n",
    "                            sleep(1)\n",
    "                            continue\n",
    "                        if not response.status_code == 200:\n",
    "                            raise Exception(\n",
    "                                'API Euromonitor retornou um status inválido '\n",
    "                                + f'{response.status_code}: {response.reason}!\\n'\n",
    "                                + response.text\n",
    "                            )\n",
    "                        if not response.content:\n",
    "                            raise Exception(\n",
    "                                \"API Euromonitor não retornou um conteúdo para chamda HTTP!\"\n",
    "                            )\n",
    "\n",
    "                    except Exception as err:\n",
    "                        raise Exception(\n",
    "                            f\"Falha ao tentar obter dados da API Euromonitor. Erro: {err}\"\n",
    "                        )\n",
    "\n",
    "                    logging.info('Transformando resposta em JSON')\n",
    "                    data = json.loads(response.text)\n",
    "\n",
    "                    if int(data['total']) - offset >= 10000:\n",
    "                        offset += 10000\n",
    "                    else: \n",
    "                        has_more = False\n",
    "\n",
    "                    logging.info('Transformando JSON em dataframe do PANDAS')\n",
    "                    tmp_df = pd.json_normalize(\n",
    "                        data[\"marketSizes\"],\n",
    "                        \"data\",\n",
    "                        [\n",
    "                            \"researchYear\",\n",
    "                            \"geographyId\",\n",
    "                            \"geographyName\",\n",
    "                            \"categoryId\",\n",
    "                            \"categoryName\",\n",
    "                            \"industry\",\n",
    "                            \"dataTypeId\",\n",
    "                            \"dataType\",\n",
    "                            \"unitName\",\n",
    "                            \"inflationType\",\n",
    "                            \"exchangeRateName\",\n",
    "                            \"perCapitaName\",\n",
    "                            \"unitMultiplier\",\n",
    "                            \"isDefaultDataType\",\n",
    "                        ],\n",
    "                        record_prefix=\"issue_level_problem_\",\n",
    "                        )\n",
    "\n",
    "                    logging.info('Realizando merge do dataframe')\n",
    "\n",
    "                    if df is not None:\n",
    "                        df = pd.concat([df, tmp_df])\n",
    "                    else:\n",
    "                        df = tmp_df\n",
    "\n",
    "                c += 1\n",
    "            logging.info(f'Chunk Categoria concluída')\n",
    "            j += 1\n",
    "\n",
    "        df.columns = df.columns.str.upper()\n",
    "\n",
    "        drop_directory(LND, adl, schema=Constants.schema, table=Constants.table)\n",
    "\n",
    "        parquet_file_name = Constants.tmp + f'{Constants.schema}_{Constants.table}.parquet'\n",
    "\n",
    "        df.to_parquet(parquet_file_name, index=False)\n",
    "\n",
    "        upload_file(\n",
    "            LND,\n",
    "            adl,\n",
    "            schema=Constants.schema,\n",
    "            table=Constants.table,\n",
    "            file=parquet_file_name,\n",
    "        )\n",
    "\n",
    "        if kwargs[\"reload\"] is False:\n",
    "            call_redis(\"set\", Constants.key_name, str(date.today()))\n",
    "\n",
    "        log_status(\"ok\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        shutil.rmtree(Constants.tmp)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(**kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "great_expectations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
